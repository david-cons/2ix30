{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas        Tested version: 2.0.3   Your version: 2.0.3\n",
      "numpy         Tested version: 1.21.5  Your version: 1.23.5\n",
      "matplotlib    Tested version: 3.5.3   Your version: 3.7.0\n",
      "scikit-learn  Tested version: 1.2.2   Your version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "import time, matplotlib, sklearn\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# the data intro has been tested with the following versions\n",
    "print(\"pandas        Tested version: 2.0.3   Your version: %s\" % pd.__version__)\n",
    "print(\"numpy         Tested version: 1.21.5  Your version: %s\" % np.__version__)\n",
    "print(\"matplotlib    Tested version: 3.5.3   Your version: %s\" % matplotlib.__version__)\n",
    "print(\"scikit-learn  Tested version: 1.2.2   Your version: %s\" % sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "If you put the data set in the same folder as this notebook, you can use the following code to load the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_v2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m description_dict \u001b[38;5;241m=\u001b[39m description\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_v2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_v2.csv'"
     ]
    }
   ],
   "source": [
    "# description\n",
    "description = pd.read_csv('data/WiDS_Datathon_2020_Dictionary.csv')\n",
    "description_dict = description.set_index('Variable Name').to_dict(orient='index')\n",
    "# data\n",
    "df = pd.read_csv('training_v2.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The dataset contains many different variables, including:\n",
    "\n",
    "#### Target variable\n",
    "* *hospital_death*: 'Whether the patient died during this hospitalization.\n",
    "\n",
    "#### Identifiers\n",
    "* *patient_id*: Unique identifier associated with a patient\n",
    "* *encounter_id*: Unique identifier associated with a patient unit stay\n",
    "* *hospital_id*: Unique identifier associated with a hospital\n",
    "* *icu_id*: A unique identifier for the unit to which the patient was admitted\n",
    "\n",
    "#### Demographics\n",
    "* *age*: The age of the patient on unit admission.\n",
    "* *bmi*: The body mass index of the person on unit admission.\n",
    "* *ethnicity*: The common national or cultural tradition which the person belongs to.\n",
    "* *gender*: The genotypical sex of the patient.\n",
    "* *height*: The height of the person on unit admission\n",
    "\n",
    "#### Health indicators\n",
    "A few examples:\n",
    "* *elective_surgery*: Whether the patient was admitted to the hospital for an elective surgical operation\n",
    "* *h1_diasbp_invasive_max*: The patient's highest diastolic blood pressure during the first hour of their unit stay, invasively measured\n",
    "* *h1_diasbp_invasive_min*: The patient's lowest diastolic blood pressure during the first hour of their unit stay, invasively measured\n",
    "* *gcs_verbal_apache*: The verbal component of the Glasgow Coma Scale measured during the first 24 hours which results in the highest APACHE III score\n",
    "* *immunosuppression*: Whether the patient has their immune system suppressed within six months prior to ICU admission for any of the following reasons; radiation therapy, chemotherapy, use of non-cytotoxic immunosuppressive drugs, high dose steroids (at least 0.3 mg/kg/day of methylprednisolone or equivalent for at least 6 months)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can retrieve the description of a variable in the data set from the description dictionary as follows\n",
    "description_dict['immunosuppression']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "This is a real-world data set, meaning that it is **messy**. Two key difficulties are categorial features and missing values.\n",
    "\n",
    "> **To avoid information leakage, any pre-processing steps must be based on the training data only.** For example, when we compute the mean, this must be computed based on the training data set.\n",
    "\n",
    "### Categorical Features\n",
    "Many (implementations of) machine learning algorithms cannot handle categorical features automatically. This is often dealt with through *one-hot-encoding*, where each category of a feature is transformed into a binary feature.\n",
    "\n",
    "When a feature contains many categories, this results in a very sparse data set with many features. As such, it can be worthwile to use domain expertise to merge particular categories in order to reduce the number of one-hot-encoded features.\n",
    "\n",
    "### Missing Values\n",
    "The data set contains a lot of missing values (around 35% of the values is missing). There are several ways to deal with this, some ideas to try:\n",
    "\n",
    "* Replace missing values with the mean (numerical features) or median (categorical features), e.g., using [`SimpleImputer`](https://scikit-learn.org/stable/modules/impute.html#univariate-feature-imputation).\n",
    "* Drop features with many missing values.\n",
    "* Model-based imputation strategies, such as [KNNImputer](https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation).\n",
    "* Domain-knowledge inspired replacement. For example, for features related to medical measurements, it is expected that the entered data is abnormal in some way. As such, replacing by the mean or median can paint a skewed picture. One way to deal with this would be to identify a normal range for different measurements, based on domain expertise. *Note: this is a very time consuming strategy which we do not necessarily recommend in the time span of this project.*\n",
    "\n",
    "We encourage you to try several approaches and see what works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of  Minimal Pre-Processing\n",
    "Below you can find an example of pre-processing the data set for classification. We showcase both 'manual' pre-processing steps through `pandas` as well as a (small) scikit-learn `Pipeline`. Feel free to use whatever you are most comfortable with in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 # proportion for train versus test+val split\n",
    "val_size = 0.5 # proportion for test versus val split\n",
    "random_state = 42  # random state is used to set a seed for randomness, which is only relevant for reproducibility purposes\n",
    "max_missing = 0.8  # maximum percentage of missing values for a column to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# save features\n",
    "X = df.copy().drop(['hospital_death', 'patient_id', 'encounter_id', 'hospital_id', 'icu_id', # drop identifiers\n",
    "                    'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', # drop APACHE scores\n",
    "                    'apache_2_bodysystem'], # drop because of similarity with apache_3j_bodysystem\n",
    "                   axis=1)\n",
    "# save target variable\n",
    "y = df['hospital_death'].copy()\n",
    "# save APACHE scores for later evaluation on train / test / validation data\n",
    "y_apache = df['apache_4a_hospital_death_prob'].copy()\n",
    "\n",
    "\"\"\" SPLIT DATA SET \"\"\"\n",
    "# split the dataset into train and test+validation set\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_apache_train,\n",
    "    y_apache_test,\n",
    "    ) = train_test_split(X, y, y_apache, \n",
    "                         test_size=test_size, # used for testing and validation\n",
    "                         random_state=random_state # for reproducibility\n",
    "                        ) \n",
    "# split the test set into test + validation set\n",
    "(\n",
    "    X_val,\n",
    "    X_test,\n",
    "    y_val,\n",
    "    y_test,\n",
    "    y_apache_val,\n",
    "    y_apache_test,\n",
    "    ) = train_test_split(X_test, y_test, y_apache_test, \n",
    "                         test_size=val_size, # used for testing and validation\n",
    "                         random_state=random_state # for reproducibility\n",
    "                        ) \n",
    "\n",
    "\"\"\"MISSING VALUES\"\"\"\n",
    "# drop columns with many missing values\n",
    "missing = X_train.isna().sum() > max_missing * len(X_train)\n",
    "missing = missing[missing].index\n",
    "X_train = X_train.drop(missing, axis=1)\n",
    "X_val = X_val.drop(missing, axis=1)\n",
    "X_test = X_test.drop(missing, axis=1)\n",
    "\n",
    "\"\"\"FURTHER PROCESSING PIPELINE\"\"\"\n",
    "# define pre-processing steps for numerical features\n",
    "num_transformer = Pipeline(steps=[(\"constant\", VarianceThreshold()), # remove constant features\n",
    "                                  (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                                 ])\n",
    "# define preprocessing steps for categorical features\n",
    "cat_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop='first', sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "# create preprocessing pipeline\n",
    "prep_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, make_column_selector(dtype_exclude=object)), # apply to columns NOT of type object (int or float)\n",
    "        ('cat', cat_transformer, make_column_selector(dtype_include=object)) # apply to columns of type object\n",
    "    ])\n",
    "# pipeline\n",
    "prep_pipeline.fit(X_train, y_train)\n",
    "display(prep_pipeline) # disply preprocessing pipeline\n",
    "\n",
    "# transform data sets\n",
    "X_train = pd.DataFrame(prep_pipeline.transform(X_train), columns=prep_pipeline.get_feature_names_out())\n",
    "X_val = pd.DataFrame(prep_pipeline.transform(X_val), columns=prep_pipeline.get_feature_names_out())\n",
    "X_test = pd.DataFrame(prep_pipeline.transform(X_test), columns=prep_pipeline.get_feature_names_out())\n",
    "        \n",
    "\"\"\"PRINT STATS\"\"\"\n",
    "print(\"Time: %.2fs\" % (time.time() - start_time))\n",
    "print(\"Train set: %s rows, %s columns\" % X_train.shape)\n",
    "print(\"Validation set: %s rows, %s columns\" % X_val.shape)\n",
    "print(\"Test set: %s rows, %s columns\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression Model\n",
    "We can now train a simple logistic regression model.\n",
    "\n",
    "> **Warning**. The following code will lead to a convergence warning. To solve this \"issue\", you can increase `max_iter` and/or apply a `sklearn.preprocessing.StandardScaler()`. However, the model still performance reasonably well even without convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# train logistic regression model\n",
    "lr = LogisticRegression(penalty='l2', solver='saga')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Time: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# APACHE IV Scores\n",
    "APACHE (\"Acute Physiology and Chronic Health Evaluation\") is a scoring system assessing severity of illness and prognoses of ICU patients. The scoring system has been improved over time, with APACHE II being released in 1985, APACHE III in 1991, and finally APACHE IV in 2006. APACHE IV has been evaluated and validated in patients for mortality outcome. \n",
    "\n",
    "In the dataset, the *apache_4a_hospital_death_prob* column corresponds to the APACHE IV probabilistic prediction of in-hospital mortality for the patient which utilizes the APACHE III score and other covariates, including diagnosis.\n",
    "* `-1` means the score couldn't be calculated for some reason. In particular, the patient encounter could have been a re-admission. \n",
    "* `NaN` indicates a missing score, due to e.g., a missing covariate that made it impossible to compute the score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "y_apache_train.hist()\n",
    "plt.title(\"APACHE scores (train)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "\n",
    "for columns in df.columns:\n",
    "    c.append((columns, (df[columns].isna().sum()) / len(df)))\n",
    "\n",
    "data = pd.DataFrame(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={0: \"Column\", 1: \"Metric\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop([\"level_0\", \"index\"], inplace = True, axis = 1)\n",
    "data.set_index(\"Column\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = list(data[data[\"Metric\"] >= 0.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = dropped_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels =  df[\"hospital_death\"]\n",
    "#features = df[[\"gender\", \"age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the baseline on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_baseline = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 10)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the random forest on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions_rf = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mse for the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions_baseline - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the MSE for the random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions_rf - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy, recall, precision and f-1 scores for the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    " \n",
    "print(accuracy_score(y_test, predictions_baseline))\n",
    "print(recall_score(y_test, predictions_baseline))\n",
    "print(precision_score(y_test, predictions_baseline))\n",
    "print(f1_score(y_test, predictions_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy, recall, precision and f-1 scores for the random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    " \n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, predictions_rf)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, predictions_rf)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, predictions_rf)))\n",
    "print(\"F-1 Score: {}\".format(f1_score(y_test, predictions_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf_gb = HistGradientBoostingClassifier(max_iter=100).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gb = clf_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, predictions_gb)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, predictions_gb)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, predictions_gb)))\n",
    "print(\"F-1 Score: {}\".format(f1_score(y_test, predictions_gb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst = XGBClassifier(n_estimators=2, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "predictions_xgb = bst.predict(X_test)\n",
    " \n",
    "print(accuracy_score(y_test, predictions_xgb))\n",
    "print(recall_score(y_test, predictions_xgb))\n",
    "print(precision_score(y_test, predictions_xgb))\n",
    "print(f1_score(y_test, predictions_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gd = clf.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, predictions_gd)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, predictions_gd)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, predictions_gd)))\n",
    "print(\"F-1 Score: {}\".format(f1_score(y_test, predictions_gd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {\n",
    "    'baseline': f1_score(y_test, predictions_baseline),\n",
    "    'rf': f1_score(y_test, predictions_rf),\n",
    "    'gb': f1_score(y_test, predictions_gb),\n",
    "    'xgb': f1_score(y_test, predictions_xgb),\n",
    "    'gd': f1_score(y_test, predictions_gd)\n",
    "}\n",
    "sorted_f1_scores = sorted(f1_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_f1_scores = pd.DataFrame(sorted_f1_scores, columns = [\"Model\", \"F-1 Score\"])\n",
    "\n",
    "baseline_f1_score = sorted_f1_scores.iloc[len(sorted_f1_scores) - 1]['F-1 Score']\n",
    "sorted_f1_scores['Percentage Increase'] = ((sorted_f1_scores['F-1 Score'] - baseline_f1_score) / baseline_f1_score) * 100\n",
    "\n",
    "\n",
    "print(sorted_f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairlearn\n",
    "from fairlearn.metrics import MetricFrame, make_derived_metric\n",
    "from sklearn.metrics import precision_score\n",
    "from fairlearn.metrics import selection_rate, count, false_positive_rate, false_negative_rate\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "mf = MetricFrame(metrics={'selection rate (COMPAS)' : selection_rate}, \n",
    "                 y_true = y_test[\"hospital_death\"], \n",
    "                 y_pred = predictions,\n",
    "                 sensitive_features = y_test[\"gender\"])\n",
    "# print results\n",
    "display(mf.by_group)\n",
    "print(\"Overall SR: %.2f\" % mf.overall[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize demographic parity as the max difference between groups\n",
    "print(\"demographic parity diff: %.2f\" % mf.difference(method='between_groups')[0])\n",
    "\n",
    "# summarize demographic parity using the metric (this gives the exact same result as mf.difference())\n",
    "dpd = demographic_parity_difference(y_true=data['two_year_recid'], \n",
    "                                    y_pred=data['decile_score_cutoff'], \n",
    "                                    sensitive_features=data['race'], \n",
    "                                    method='between_groups') # summarize as the max difference between any of the groups\n",
    "print(\"demographic parity diff: %.2f\" % dpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = clf.predict_proba(X_test)\n",
    "predictions_gb = clf_gb.predict(X_test)\n",
    "probabilities = pd.DataFrame(probabilities, columns = [\"Survival\", \"Death\"])\n",
    "predictions_gb = pd.DataFrame(predictions_gb, columns = [\"Decision\"])\n",
    "X_test_sensitive = X_test[[\"cat__gender_M\"]]\n",
    "\n",
    "gb_df = probabilities.merge(predictions_gb, left_index = True, right_index = True)\n",
    "gb_df = gb_df.merge(X_test_sensitive, left_index = True, right_index = True)\n",
    "gb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df[(gb_df[\"cat__gender_M\"] == 0.0) & (gb_df[\"Decision\"] == 0)][\"Decision\"].count() / gb_df[gb_df[\"cat__gender_M\"] == 0.0][\"Decision\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df[(gb_df[\"cat__gender_M\"] == 1.0) & (gb_df[\"Decision\"] == 0)][\"Decision\"].count() / gb_df[gb_df[\"cat__gender_M\"] == 1.0][\"Decision\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rows in gb_df.index:\n",
    "    gb_df.sort_values( by = \"Survival\", axis=0, ascending = False, inplace = True)\n",
    "    female_survival = gb_df[(gb_df[\"cat__gender_M\"] == 0.0) & (gb_df[\"Decision\"] == 0)][\"Decision\"].count() / gb_df[gb_df[\"cat__gender_M\"] == 0.0][\"Decision\"].count()\n",
    "    male_survival = gb_df[(gb_df[\"cat__gender_M\"] == 1.0) & (gb_df[\"Decision\"] == 0)][\"Decision\"].count() / gb_df[gb_df[\"cat__gender_M\"] == 1.0][\"Decision\"].count()\n",
    "    while female_survival > male_survival:\n",
    "        gb_df.iloc[rows][\"Decision\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf_gb = HistGradientBoostingClassifier(max_iter=100).fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gb = clf_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, predictions_gb)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, predictions_gb)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, predictions_gb)))\n",
    "print(\"F-1 Score: {}\".format(f1_score(y_test, predictions_gb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions_gb)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = conf_matrix[0, 1]  # False positives\n",
    "TN = conf_matrix[0, 0]  # True negatives\n",
    "FN = conf_matrix[1, 0]  # False negatives\n",
    "TP = conf_matrix[1, 1]  # True positives\n",
    "\n",
    "# Compute FPR and FNR\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = {\n",
    "    'FP': 1,  # Cost of false positive\n",
    "    'FN': 13.1002   # Cost of false negative\n",
    "}\n",
    "\n",
    "# Compute sample weights based on misclassification costs\n",
    "sample_weights = []\n",
    "for y_true in y_train:\n",
    "    if y_true == 0:\n",
    "        sample_weights.append(cost_matrix['FP'])  # Assign higher weight to false positives\n",
    "    else:\n",
    "        sample_weights.append(cost_matrix['FN'])  # Assign higher weight to false negatives\n",
    "\n",
    "# Instantiate the GradientBoostingClassifier and pass the sample weights\n",
    "clf = HistGradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions\n",
    "predictions_gb = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, predictions_gb)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, predictions_gb)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, predictions_gb)))\n",
    "print(\"F-1 Score: {}\".format(f1_score(y_test, predictions_gb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions_gb)\n",
    "conf_matrix\n",
    "FP = conf_matrix[0, 1]  # False positives\n",
    "TN = conf_matrix[0, 0]  # True negatives\n",
    "FN = conf_matrix[1, 0]  # False negatives\n",
    "TP = conf_matrix[1, 1]  # True positives\n",
    "\n",
    "# Compute FPR and FNR\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "FNR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Gradient Boosting')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
